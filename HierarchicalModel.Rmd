---
title: "Simple Models"
author: "Daniel Hopkins & Rob Verbeek"
date: "12/1/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(rstan)
library(ggplot2)
library(corrplot)
library(rstanarm)
library(scatterplot3d)
library("bayesplot")
theme_set(bayesplot::theme_default(base_family = "sans"))
SEED = 1234 
```

## Reading in the ESS Data

```{r selecting data rows and variables}
# N = 1000 # Number of sample points

set.seed(1234)

M = length(ESSData$lrscale)
ESSData <- read.csv(file="data/filtered_data2.csv", header=TRUE, sep=",")



country = ESSData$cntry
age = 2016 - ESSData$yrbrn
age = age/max(age)
drops = c("cntry","yrbrn")
ESSData = ESSData[,!(names(ESSData) %in% drops)] / 10
ESSData = data.frame(age,ESSData)

SAMPLESIZE = 5000

sample_rows = sample(seq(1,M),SAMPLESIZE)

test_rows = sample(seq(1,SAMPLESIZE),1000)

sample_data = data.frame(ESSData[sample_rows,])

training_data = data.frame(sample_data[-test_rows,])

test_data = data.frame(sample_data[test_rows,])


```

```{r correlation matrix}
c = cor(data.frame(small_sample))
lrscale_cor = c["lrscale",]
best_variables = lrscale_cor[order(abs(lrscale_cor),decreasing=TRUE)][1:21]
best_columns = order(abs(lr_cor),decreasing=TRUE)[1:21]
sample_data_best_vars = sample_data[best_columns]
sample_data_best_vars = cbind(country[sample_rows], sample_data_best_vars)
best_variables
```


```{r}
t_prior <- student_t(df = 5, location = 0.5, scale = 0.1)
fit_lm_1 <- stan_glmer(lrscale ~ gincdif + dfincac | country[sample_rows], data=sample_data_best_vars, prior = t_prior, prior_intercept = t_prior)
print(fit_lm_1, digits=2)
```

```{r, fig.height=5}
polandRows = which(sample_data_best_vars$`country[sample_rows]`=="PL")
ggplot(sample_data_best_vars[polandRows,], aes(jitter(gincdif,1), jitter(lrscale,1))) +
  geom_point() +
  geom_abline(intercept = coef(fit_lm_1)$'country[sample_rows]'[17,2], slope = coef(fit_lm_1)$'country[sample_rows]'[17,1] ) +
  labs(x = "Government should reduce income differences", y = "Political Alignment")
```

```{r, fig.height=5}
swedenRows = which(sample_data_best_vars$`country[sample_rows]`=="SE")
ggplot(sample_data_best_vars[swedenRows,], aes(jitter(gincdif,1), jitter(lrscale,1))) +
  geom_point() +
  geom_abline(intercept = coef(fit_lm_1)$'country[sample_rows]'[20,2], slope = coef(fit_lm_1)$'country[sample_rows]'[20,1] ) +
  labs(x = "Government should reduce income differences", y = "Political Alignment")
```

ADD HERE: TWO LINES DEPENDING ON COUNTRY
```{r, fig.height=5}
# ESSData$cntry
# colors <- ifelse(small_sample$country=="NL", "black", "gray")
sims <- as.matrix(fit_lm_1)
n_sims <- nrow(sims)
subset <- sample(n_sims, 1000)
plot(jitter(small_sample$gincdif,1), jitter(small_sample$lrscale,1), xlab="Government should reduce income differences", ylab="Political Alignment")
for(i in subset){
  abline(sims[i,1], sims[i,2], col="gray")
}
abline(coef(fit_lm_1))
```
```{r, fig.height=5}
ggplot(small_sample, aes(jitter(gincdif,1), jitter(lrscale,1))) +
  geom_point() +
  geom_abline(intercept = coef(fit_lm_1)[1], slope = coef(fit_lm_1)[2]) +
  labs(x = "Government should reduce income differences", y = "Political Alignment")
```
```{r}
fit_lm_2 <- stan_glm(lrscale ~ gincdif + sbbsntx, data=sample_data_best_vars)
summary(fit_lm_2,digits=2)
```

```{r logistic experiment}
fit_lm_logit <- stan_glm(lrscale ~ gincdif, family = binomial(link = "logit"), data=sample_data_best_vars)
summary(fit_lm_logit,digits=2)
```



```{r}

fit_lm_3 <- stan_glm(lrscale ~ ., data=sample_data_best_vars)
print(fit_lm_3)
summary(fit_lm_3,digits=2)
```

```{r}
accuracy <- function(test_data, w) {
  correct = 0
  wrong = 0
  for(n in seq(1:length(test_))) {
    cols = seq(2,length(w))
    prediction[n] = (w[cols] %*% as.numeric(sample_data_best_vars[n,cols]) + w[1])
  }

  for(n in seq(1,length(test_data[,1]))) {
    if((prediction[n]<0.5 && smaller_sample$lrscale[n]<0.5) || (prediction[n]>0.5 && smaller_sample$lrscale[n]>0.5)) {
      correct = correct + 1
  }
  else if((prediction[n]<0.5 && smaller_sample$lrscale[n]>0.5) || (prediction[n]>0.5 && smaller_sample$lrscale[n]<0.5)) {
    wrong = wrong + 1
  }
  error = error + abs(prediction[n] - smaller_sample$lrscale[n])
}
}
correct = 0
wrong = 0
error = 0
prediction = seq(1,1000)
w = fit_lm_3$coefficients

for(n in seq(1:1000)) {
  prediction[n] = (w[2:21] %*% as.numeric(smaller_sample[n,2:21]) + w[1])
}


for(n in seq(1,1000)) {
  if((prediction[n]<0.5 && smaller_sample$lrscale[n]<0.5) || (prediction[n]>0.5 && smaller_sample$lrscale[n]>0.5)) {
    correct = correct + 1
  }
  else if((prediction[n]<0.5 && smaller_sample$lrscale[n]>0.5) || (prediction[n]>0.5 && smaller_sample$lrscale[n]<0.5)) {
    wrong = wrong + 1
  }
  error = error + abs(prediction[n] - smaller_sample$lrscale[n])
}
print("Average Prediction Error: ")
hist(ESSData$lrscale)
error / 1000
correct
wrong
```
```{r loo comparison}
loo_1 <- loo(fit_lm_1)
loo_2 <- loo(fit_lm_2)
loo_3 <- loo(fit_lm_3)
loo_logit <- loo(fit_lm_logit)
loo_compare(loo_1, loo_3)
loo_1
```