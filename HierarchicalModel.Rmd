---
title: "Simple Models"
author: "Daniel Hopkins & Rob Verbeek"
date: "12/1/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(rstan)
library(ggplot2)
library(corrplot)
library(rstanarm)
library("bayesplot")
theme_set(bayesplot::theme_default(base_family = "sans"))
SEED = 1234 
options(mc.cores = parallel::detectCores())
```

## Reading in the ESS Data

## Data filtering
The ESS dataset is very large, with a lot of different types of values and country-specific questions. So before running our models, we cleaned our data. Cleaning the data consists of the following steps:

Remove country-specific data:
- We want all variables to be available for all countries, so we remove country-specific data.

Remove nominal data:
- The dataset has a lot of questions that are nominal (things like job-type, political party voted for). These are filtered out, because they cannot be put on a scale.

Remove sparse questions:
- We remove the questions that have more tan 10% invalid answers (e.g. not answered, no preference, etc..). This is mainly done so that in a later stage of filtering, these questions don't cause the filtering of too many datapoints.

Change scales:
- The questions come in a lot of different scales, like 1-10, 1-5, 1-4 but also yes-no questions. These questions are all scaled to the 1-1- scale. For most scales this is done using a simple transformation, the yes-no questions are mapped to the values 7 and 3.


```{r selecting data rows and variables}
# N = 1000 # Number of sample points

set.seed(1234)

ESSData <- read.csv(file="data/filtered_data2.csv", header=TRUE, sep=",")
M = length(ESSData$lrscale)



country = ESSData$cntry
age = 2016 - ESSData$yrbrn
age = age/max(age)
drops = c("cntry","yrbrn")
ESSData = ESSData[,!(names(ESSData) %in% drops)] / 10
ESSData = data.frame(age,ESSData)

SAMPLESIZE = 5000

sample_rows = sample(seq(1,M),SAMPLESIZE)

test_rows = sample(seq(1,SAMPLESIZE),1000)

sample_data = data.frame(ESSData[sample_rows,])

training_data = data.frame(sample_data[-test_rows,])

test_data = data.frame(sample_data[test_rows,])


```

```{r correlation matrix}
best_5 = c(29,22,41,79,85)
sample_data_best_5 = cbind(sample_data$lrscale,sample_data[,best_5])
sample_data_best_5 = cbind(country[sample_rows],sample_data_best_5)
colnames(sample_data_best_5)[1] = "country"
colnames(sample_data_best_5)[2] = "lrscale"
```
## Pooled model
The pooled model considers all data the same, thus not take into account the country each datapoint is from. It fits one linear model to predict the left-right scale, based on all input variables. 

## Partially pooled
The previous model is pooled, assuming there is no differences between countries. The partially pooled model allows for differentation between countries. Each country will have it's own intecept and slope per variable, but these parameters are fitted to an overall distribution. This still allows the model to generalize over the entire dataset, while being able to fit a more narrow distribution on each country individually.

```{r cache=TRUE}
# Try horseshoe prior
t_prior <- student_t(df = 5, location = 0.5, scale = 0.1)
fit1 <- stan_glm(lrscale ~ gincdif, data=sample_data_best_5, prior = t_prior, prior_intercept = t_prior)
```

```{r cache=TRUE}
fit_hier_2 <- stan_lmer(lrscale ~ 1 + gincdif + impcntr + dfincac + rlgblg + sbsrnen + (1 + gincdif + impcntr + dfincac + rlgblg + sbsrnen | country), data=sample_data_best_5, iter=200)
print(fit_hier_2, digits=2)
```

```{r}
coefficients <- coef(fit_hier_2)[1]
```
## Interesting countries:
Sweden: Really steep slopes for most variables
Poland and Siberia: slope different sign than other countries for many variables
Italy: Very large slope for impcntr
EE: Max slope for rlgblg
LT: Min slope for impcntr
CZ: Min slope for sbsrnen

```{r}

# (0) Set axes & choose schools
y <- sample_data_best_5$lrscale
x <- sample_data_best_5$gincdif
countryid <- sample_data_best_5$country
sel.cntry <- c("SE",
             "PL",
             "SI",
             "IT",
             "EE",
             "LT",
             "CZ",
             "FI",
             "NL")

# (1) Subset 8 of the schools; generate data frame
df <- data.frame(y, x, countryid)
df8 <- subset(df, countryid %in% sel.cntry)

# (2) Assign complete-pooling, no-pooling, partial pooling estimates
a_pooled <- coef(fit1)[1]
b_pooled <- coef(fit1)[2]

a_part_pooled <- coef(fit_hier_2)$country[, 1]
b_part_pooled <- coef(fit_hier_2)$country[, 2]

df8$a_pooled <- a_pooled 
df8$b_pooled <- b_pooled

df8$a_part_pooled <- a_part_pooled[df8$countryid]
df8$b_part_pooled <- b_part_pooled[df8$countryid]

ggplot(data = df8, 
       aes(x = x, y = y)) + 
  facet_wrap(facets = ~ countryid, 
             ncol = 4) + 
  theme_bw() +
  geom_jitter(position = position_jitter(width = .05, 
                                         height = 0.02)) +
  geom_abline(aes(intercept = a_part_pooled, 
                  slope = b_part_pooled), 
              linetype = "solid", 
              color = "blue", 
              size = 0.5) +
  
  geom_abline(aes(intercept = a_pooled, 
                slope = b_pooled), 
            linetype = "solid", 
            color = "red", 
            size = 0.5) +
  
  scale_x_continuous(breaks = c(0, 1)) + 
  labs(title = "Complete-pooling, No-pooling, and Partial pooling estimates",
       x = "", 
       y = "Total score on coursework paper")+theme_bw( base_family = "serif")

```




```